[["index.html", "Project in Data Analytics for Decision Making Chapter 1 Introduction", " Project in Data Analytics for Decision Making Manon Verjus and Yooby Gigandet 2022-06-06 Chapter 1 Introduction Our work for the course “Project in Data Analytics for Decision Making” is to predict the credit risk linked to customers for our client, a German bank. To do so, we used the CRISP-DM method (CRoss Industry Standard Process for Data Mining): Business understanding: Credit risk is defined as the risk of loss resulting from the failure by a borrower to repay the principal and interest owed to the lender. By performing a credit risk analysis, the lender determines the borrower’s ability to meet debt obligations in order to cushion itself from losses. It is therefore important to efficiently classify the risks of the credit applications. Data understanding and preparation: We study the german data set. This part focus on visualization of the data set. We observed the variables, the distribution of the data through plots and tables. The goal of this part is to well understand the data set we work with to be able to find relevant model later. Modelling: After observing our data set, we need to find which model is the most relevant for the analysis. We fitted several models to assess which one(s) is(are) the best. Evaluation: By testing several model, we can sum the output and decide the most relevant model to use. The evaluation part focuses on the application of the chosen model(s). Deployment: To finish this study, we will assess some proposals and hypothesis on the customer profiles to avoid or to favor to minimize the risk in the bank. "],["data-understanding-and-preparation.html", "Chapter 2 Data understanding and preparation 2.1 Dataset 2.2 Exploratory Data Analysis", " Chapter 2 Data understanding and preparation 2.1 Dataset To create a model that will predict whether a client application represents a risk or not, we work on a data set from our client containing data on 1000 past credit applications, described by the following variables: CHK_ACCT: The checking account status of the applicant in Deutsche Mark (DM). DURATION: The duration of the credit in months. HISTORY: The credit history of the applicant. NEW_CAR: Purpose of the credit. USED_CAR: Purpose of the credit. FURNITURE: Purpose of the credit. RADIO/TV: Purpose of the credit. EDUCATION: Purpose of the credit. RETRAINING: Purpose of the credit. AMOUNT: The credit amount. SAV_ACCT: The average balance in savings account in Deutsche Mark (DM). EMPLOYMENT: If the applicant is employed and since how long. INSTALL_RATE: The installment rate as percentage of disposable income. MALE_DIV: If the applicant is male and divorced. MALE_SINGLE: If the applicant is male and single. MALE_MAR_or_WID: If the applicant is male, married or widowed. CO_APPLICANT: If the applicant has a co-applicant. GUARANTOR: If the applicant has a guarantor. PRESENT_RESIDENT: If the applicant is a resident and since how many years. REAL_ESTATE: If the applicant owns real estate. PROP-UNKN-NONE: If the applicant owns no property (or unknown). AGE: Age of the applicant. OTHER_INSTALL: If the applicant has other installment plan credit. RENT: If the applicant rents. OWN_RES: If the applicant owns residence. NUM_CREDITS: Number of existing credits of the applicant at our client bank. JOB: The nature of the applicant’s job. NUM_DEPENDENT: Number of people for whom liable to provide maintenance. TELEPHONE: If the applicant has a phone in his or her name. FOREIGN: If the applicant is a foreign worker. RESPONSE: If the credit application is rated as “Good” or “Bad”. 2.2 Exploratory Data Analysis In this part, we thoroughly explore the data set to get a better understanding. The goal of the exploratory data analysis is to observe and interpret our data thanks to visualization methods, as plots. 2.2.1 Inacurracies By doing an exploratory data analysis, we find some inaccuracies and in agreement with our client, we change them as follow: One observation of the variable “AGE”: 75 instead of 125 years old. One observation of the variable “EDUCATION”: 1 instead of -1. One observation of the variable “GUARANTOR”: 1 instead of 2. Then, we decided to split the database in 2 parts: the first part consider only the good clients, and the second part consider only the bad clients. This will help us to study the specificities of both profiles. 2.2.2 Unbalanced observations To start, we notice an important point to consider: the data set is heavily unbalanced. As you can see on the following plot, it contains 700 credit applications rated as good versus 300 credit applications rated as bad. We will need to balance the data set for our modelling. 2.2.3 Visualization To have a better visualization of our variables. We did some box plot which show the distribution of the data. This first box plot A shows that bad clients mostly asked for longer duration credit than good clients. This could be a reason why they received a refusal. The second box plot B shows that the age of clients does not seem to be a key criteria but the amount of the credit (box plot C) seems to be more important as most of the good clients asked for a smaller amount. Then, we explored the distribution of the financial variables. The first graph A presents the situation with past credits. The behavior for good and bad clients is almost the same which does not allow us to make a clear difference. On the graph B we can see that most of the clients have small savings or even no savings at all. Most of the clients have already 1 or 2 credits at this bank. Almost none of them ask for a third or fourth credit. On the histogram D we see that the amount of money on the account not so important. Indeed, most of the good client do not even have a checking account. The graphs below displays furniture and products owned by the clients. Most of the time the credits are not very favorable to finance products. However, new cars are more appreciated by banks than used cars and radio/TV are more financed than furniture. As we can see on the graph before, most of the time, if the client ask a credit to pay education, the bank will refuse (see plot C), even if the client is good. It is slightly the same for retraining (see plot D). Most of the good client have a job for more than a year and are skilled employees, as displayed in plots A and B. #&gt; $`1` #&gt; #&gt; $`2` #&gt; #&gt; attr(,&quot;class&quot;) #&gt; [1] &quot;list&quot; &quot;ggarrange&quot; The graph A presents the qualification of client depending of the duration stays in their home. This criteria does not seem to be really indicative even if the most good clients live in their place since more than 4 years. The installment rate does not seem to impact the qualification of the client neither as most of the good and bad clients are rated by 4 (see graph B). Owning a real estate is not the key to be perceived as a good client neither. As the graph C prove, a lot of good clients do not have any real estate. But at the opposite having no property is a bad situation in the case of asking for a credit. The graphs show that customer that own their residence are mainly considered as good ones (see plot E). However, renters are not really appreciated by the bank (see plot G). And a surprising point is that a guarantor is definitely not a must to receive a credit, as we can see on the plot F. Now, let’s see some demographic data. About the demographic data of an applicant, we can see on the plots A, C and D that bad clients are generally male married and divorced, male and divorced or foreign workers. However, single man are more favor to be receive their credit. As we can see on the 4 plots before, the population of good clients basically do not have co-applicants and they do not have other installment plan neither for majority of them. The name’s telephone does not seem to be important as a lot of clients have and have not the telephone on their name. However, most of the clients are not liable to provide maintenance. We can see below the mean of good clients and the mean of bad clients. It is important to keep in account that the sample of good clients is much higher than the number of bad clients so our result presents some bias. The matrix below present the correlations between variables. To read in a easiest way, we separated the variables in categories. As before, the categories were created based on their area. We do not observe any high correlation between variables in none of our correlation matrix. This could be due to the fact that we chose badly the variables in the matrix. However, we present some strong result. 2.2.4 Profile of a good client The following part of the project is focus on defining a typical profile of a good client. The goal is to define an average good client based on the average of all the variables defined. First, we cleaned the data set created at the beginning which contain only good clients to have the average of each variable. Then, we created a plot with these average data. The lollipop plot below present the mean profile to be qualified as a good client. From these results, most of them ask for a new car, rent their flat but have real estate. The good client in average has a quite good amount of money and has a guarantor. These results are quite different than what we presented before. 2.2.5 Profile of a bad client Then, we used exactly the same approach to build the typical profile of a bad client and identify the average variables that qualify a bad client in this bank. As we can see on the orange lollipop plot, the result is different. Most of the bad clients rent their flat. This criteria sounds really important to qualify a client. Almost all of them do not have any other credit in the bank and they have other installment plan credits. 2.2.6 Variable selection The following plot shows a selection of the most important variables of our data frame. The two main disadvantages of these methods are: The increasing over fitting risk when the number of observations is insufficient. The significant computation time when the number of variables is large. The result below displays that we seem to have 6 relevant variables: checking the account, the duration of the credit asked, the history of previous credits, the savings, the amount of money owned by the applicant and the real estate owned. #&gt; Warning in train.default(x, y, weights = w, ...): You are trying to #&gt; do regression and your outcome only has two possible values Are you #&gt; trying to do classification? If so, use a 2 level factor as your #&gt; outcome column. #&gt; Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info #&gt; = trainInfo, : There were missing values in resampled performance #&gt; measures. #&gt; rpart variable importance #&gt; #&gt; only 20 most important variables shown (out of 30) #&gt; #&gt; Overall #&gt; CHK_ACCT 0.1141 #&gt; DURATION 0.0803 #&gt; HISTORY 0.0767 #&gt; SAV_ACCT 0.0684 #&gt; AMOUNT 0.0516 #&gt; REAL_ESTATE 0.0343 #&gt; INSTALL_RATE 0.0000 #&gt; CO_APPLICANT 0.0000 #&gt; USED_CAR 0.0000 #&gt; FURNITURE 0.0000 #&gt; NUM_CREDITS 0.0000 #&gt; EMPLOYMENT 0.0000 #&gt; MALE_MAR_or_WID 0.0000 #&gt; JOB 0.0000 #&gt; AGE 0.0000 #&gt; OTHER_INSTALL 0.0000 #&gt; EDUCATION 0.0000 #&gt; OWN_RES 0.0000 #&gt; RADIO_TV 0.0000 #&gt; TELEPHONE 0.0000 "],["modelling.html", "Chapter 3 Modelling 3.1 Splitting strategies and balancing 3.2 K-Nearest Neighbors (K-NN) 3.3 Naive Bayes 3.4 Logistic Regression 3.5 Trees 3.6 Neural Network 3.7 Support Vector Machines 3.8 Random Forest 3.9 Summary 3.10 Variable Importance 3.11 Evaluation", " Chapter 3 Modelling After cleaning and visualizing the data set, we move on to the creation of models. 3.1 Splitting strategies and balancing In machine learning, a method to measure the accuracy of the models is to split the data into a training and a test set. The first subset is a portion of our data set that is fed into the machine learning model to discover and learn patterns. The other subset is to test our model. We split our data set as follows: Training set: 80% of the data Test set: the remaining 20% of the data # Splitting set.seed(346) # Creation of the index index.tr &lt;- createDataPartition(y = GermanCredit$RESPONSE, p= 0.8, list = FALSE) GermanCredit.tr &lt;- GermanCredit[index.tr,] # Training set GermanCredit.te &lt;- GermanCredit[-index.tr,] # Testing set As said in the exploratory data analysis, we notice that our data is heavily unbalanced. Outcome Frequence 0 236 1 564 Therefore, any model that favors the majority will reach an higher accuracy. However, in our case, we need to make sure to rightly classify any credit applications to avoid losses. To do so, we use a method called sub-sampling that balance the observations. It will allow us to have two equivalent samples. # Balancing n_no &lt;- min(table(GermanCredit.tr$RESPONSE)) GermanCredit.tr.no &lt;- filter(GermanCredit.tr, as_factor(RESPONSE)==0) GermanCredit.tr.yes &lt;- filter(GermanCredit.tr, as_factor(RESPONSE)==1) ## sub-sample 236 instances from the &quot;Good&quot; index.no &lt;- sample(size=n_no, x=1:nrow(GermanCredit.tr.no), replace=FALSE) ## Bind all the &quot;Bad&quot; and the sub-sampled &quot;Good&quot; GermanCredit.tr.subs &lt;- data.frame(rbind(GermanCredit.tr.no, GermanCredit.tr.yes[index.no,])) By doing so, we get the following sub sampled training set: Outcome Frequence 0 236 1 236 3.2 K-Nearest Neighbors (K-NN) A K-Nearest Neighbors tries to predict the correct class for the test data by calculating the distances between the test data and all the training points. Then to predict, it selects a number K, of the closest point of the test set (thus the name K-nearest neighbors). # K-Nearest Neighbors (K-NN) trctrl &lt;- trainControl(method = &quot;cv&quot;, number=10) # Cross-validation search_grid &lt;- expand.grid(k = seq(1, 85, by = 1)) set.seed(346) knn_cv &lt;- train(as_factor(RESPONSE)~., data = GermanCredit.tr.subs, method = &quot;knn&quot;, trControl = trctrl, metric = &quot;Accuracy&quot;, tuneGrid = search_grid) We need to select the K number of points closest that give the optimal accuracy. In this case, it is 77 We did several confusion matrix to measure the performance. The first one was with knn method. We found an accuracy of 0.615 which corresponds to well predicted clients (good and bad). The best accuracy value is 1 so 0.615 is considered as a not bad value. 3.3 Naive Bayes Then, we used a probabilistic approach with Bayes classifiers. With this method, the confusion matrix provides a better accuracy of 0.72. # Naive Bayes trctrl &lt;- trainControl(method = &quot;cv&quot;, number=10) search_grid &lt;- expand.grid( usekernel = c(TRUE, FALSE), laplace = 0:5, adjust = seq(0, 5, by = 1) ) set.seed(346) naive_bayes &lt;- train(as_factor(RESPONSE) ~., data = GermanCredit.tr.subs, method = &quot;naive_bayes&quot;, trControl=trctrl, tuneGrid = search_grid) 3.4 Logistic Regression A logistic regression is a regression adapted to binary classification. We use a cross-validation method to train our model and choose the Akaïke Information Criterion (AIC) to select the variables. The AIC is used to select the model based on the number of parameters. We choose the model with the smallest AIC. # Logistic Regression trctrl &lt;- trainControl(method = &quot;cv&quot;, number=10) set.seed(346) glm_aic &lt;- train(as_factor(RESPONSE) ~., data = GermanCredit.tr.subs, method = &quot;glmStepAIC&quot;, family=&quot;binomial&quot;, trControl=trctrl, trace=0) The following plot corresponds to the resulting confusion matrix of the logistic regression: It provides an accuracy of 0.73. 3.5 Trees The trees represent a hierarchical set of binary rules in a shape of a tree. 3.6 Neural Network Neural Network is a method based on combining several predictions of small nodes. # Neural Network (NN) trctrl &lt;- trainControl(method = &quot;cv&quot;, number=5) search_grid &lt;- expand.grid(size = 1:10, decay = seq(0, 0.5, 0.1)) set.seed(346) neural_network &lt;- train(as_factor(RESPONSE) ~., data = GermanCredit.tr.subs, method = &quot;nnet&quot;, trControl=trctrl, tuneGrid = search_grid) The confusion matrix with neural network presents a good accuracy of 0.705. 3.7 Support Vector Machines # Support Vector Machines trctrl &lt;- trainControl(method = &quot;cv&quot;, number=5) search_grid &lt;- expand.grid(C = c(0.01, 0.1, 1, 10, 100, 1000)) set.seed(346) svm &lt;- train(as_factor(RESPONSE) ~., data = GermanCredit.tr.subs, method = &quot;svmLinear&quot;, trControl=trctrl, tuneGrid = search_grid) The cinfusion matrix presents an accuracy of 0.745. 3.8 Random Forest # Random Forest trctrl &lt;- trainControl(method = &quot;cv&quot;, number=5) search_grid &lt;- expand.grid(.mtry = c(1:15)) set.seed(346) rf &lt;- train(as_factor(RESPONSE) ~., data = GermanCredit.tr.subs, method = &quot;rf&quot;, trControl = trctrl, tuneGrid = search_grid ) Again, this models shares an accuracy of 0.73. 3.9 Summary To evaluate our models, there are many metrics that can be used. We decided to choose first the accuracy and then have a look at the sensitivity and the specificity. In other words, we want to have a model with a good accuracy and the best sensitivity and specificity. Accuracy Sensitivity Specificity Support Vector Machines 0.74 0.75 0.74 Tree 0.74 0.66 0.65 Logistic Regression 0.73 0.72 0.74 Random Forest 0.73 0.69 0.75 Naive Bayes 0.72 0.81 0.68 Neural Network 0.70 0.75 0.68 K-nearest neighbors 0.62 0.47 0.68 By looking at this summary table of the models, we can see that the Logistic Regression and the Random Forest are our top models. Even if the Random Forest is slightly worse than the following models in terms of specificity and sensitivity. Therefore, we chose the two models: Logistic Regression Random Forest 3.10 Variable Importance In this part, we want to evaluate if there is room for improvement for these models, in other words, if we can remove some variables to make the analysis easier without loosing the performance. 3.10.1 Logistic Regression Accuracy Sensitivity Specificity Original Logistic Regression 0.73 0.72 0.74 Refit Logistic Regression 0.66 0.61 0.68 As we can see in the table above, we loose performance in terms of the metrics. This means that the variable importance is not that important for the logistic Regression. A good point is that we need to remind ourselves that the logistic regression already do a variable importance with the AIC criterion. 3.10.2 Random Forest Accuracy Sensitivity Specificity Original Random Forest 0.73 0.69 0.75 Refit Random Forest 0.68 0.70 0.67 Again, we lose a bit of performance in terms of the metrics. However, the model is simpler and might be easier to understand. 3.11 Evaluation "],["deployment.html", "Chapter 4 Deployment", " Chapter 4 Deployment "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
